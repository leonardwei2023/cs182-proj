{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e958589",
   "metadata": {},
   "source": [
    "# Point Net Homework\n",
    "\n",
    "The following homework is based on the paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Qi et al.\n",
    "\n",
    "In this paper, the authors present a novel neural network architecture that takes in point clouds as inputs. This network can be used across many tasks including object segmentation, part segmentation, and scene semantic parsing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacee2e0",
   "metadata": {},
   "source": [
    "## 1. 3D Data Representation\n",
    "\n",
    "There are various ways one could represent 3D before inputting into a neural network. Histocially, networks have used convolutional architecures, which require inputs to be highly standardized. As such, researchers will often convert their data into 3D voxel grids or collections of images. \n",
    "\n",
    "As stated by the authors, these data formats are volumous, due to data redundancy, and may introduce quantization artifacts. As such, we will be focusing on 3D Meshes and Point Clouds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f7c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import ShapeNetDataset\n",
    "#from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56592ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teapot_file_path = '../cs182-proj/images/canvas3D-master/teapot.ply'\n",
    "points_data = pv.read(teapot_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b5a18",
   "metadata": {},
   "source": [
    "### 3D Mesh\n",
    "\n",
    "The 3D Mesh is generated using a set of polygons to represent the structure of the object. It is determined using points with X, Y, Z coordinates. These points are connected to make polygons, most commonly triangles and quads. Due to the complexity of meshes and potential combinatorial irregularities, the authors choose not to represent their data in this format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3bb7799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#points_data.plot(jupyter_backend='panel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384c701c",
   "metadata": {},
   "source": [
    "### Point Cloud\n",
    "Point Clouds are a basic data format in which the points are represented in 3D space, using X, Y, and Z coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b53a669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsphere = pv.Sphere(radius=0.05)\\npc = points_data.glyph(scale=False, geom=sphere, orient=False)\\npc.plot(cmap='Reds', jupyter_backend='panel')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sphere = pv.Sphere(radius=0.05)\n",
    "pc = points_data.glyph(scale=False, geom=sphere, orient=False)\n",
    "pc.plot(cmap='Reds', jupyter_backend='panel')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf95112",
   "metadata": {},
   "source": [
    "## 2. The Model Architecture\n",
    "\n",
    "The archicture of PointNet is as follows:\n",
    "![plot](images/model.png)\n",
    "\n",
    "In the following sections we will implement pieces of the architecture and see how they impact the downstream performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924b2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(preds, labels, feature_transform, reg=0.0001):\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    def feat_loss(A):\n",
    "        I = torch.eye(64, requires_grad=True).expand(A.size(0), -1, -1)\n",
    "        AA_T = torch.bmm(A, A.transpose(1, 2))\n",
    "        return torch.linalg.norm(I - AA_T, ord='fro', dim=(1,2))\n",
    "    return loss(preds, labels) + reg * torch.mean(feat_loss(feature_transform))\n",
    "\n",
    "def train(model, trainset, validset, optimizer, epochs=10, batch_size=32, device=torch.device('cpu')):\n",
    "    train_dataloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(validset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    train_losses, train_accs = [], []\n",
    "    valid_losses, valid_accs = [], []\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # Train and get training loss and accuracy\n",
    "        train_loss, train_num_correct = [], []\n",
    "        for x, y in tqdm(train_dataloader, unit='batch'):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred, feat = model(x)\n",
    "            loss = loss_fn(pred, y, feat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            train_num_correct.append(torch.sum(pred.argmax(1) == y).item())\n",
    "        train_losses.append(np.mean(train_loss))\n",
    "        train_accs = train_num_correct / len(trainset)\n",
    "\n",
    "        model.eval()\n",
    "        # Get validation loss and accuracy\n",
    "        with torch.no_grad():\n",
    "            valid_loss, valid_num_correct = [], []\n",
    "            for x, y in tqdm(valid_dataloader, unit='batch'):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                pred, feat = model(x)\n",
    "                loss = loss_fn(pred, y, feat)\n",
    "                valid_loss.append(loss.item())\n",
    "                valid_num_correct.append(torch.sum(pred.argmax(1) == y).item())\n",
    "        \n",
    "        print('Finished Epoch {}\\n training loss: {}, validation loss: {} \\n training accuracy: {}, validation accuracy: {}'\n",
    "                .format(epoch+1, train_losses[-1], valid_losses[-1], train_accs[-1], valid_accs[-1]))\n",
    "\n",
    "    return train_losses, valid_losses, train_accs, valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35cdbfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "\n",
    "trainset = ShapeNetDataset(\"datasets/ModelNet10\", train=True, n=n)\n",
    "testset = ShapeNetDataset(\"datasets/ModelNet10\", train=False, n=n)\n",
    "\n",
    "dataset_length = len(trainset)\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.3\n",
    "\n",
    "train_len = int(dataset_length * train_ratio)\n",
    "valid_len = dataset_length - train_len\n",
    "\n",
    "\n",
    "\n",
    "trainset, validset = random_split(trainset, [train_len, valid_len])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9be2e69",
   "metadata": {},
   "source": [
    "### 2.1 Baseline Architecture\n",
    "\n",
    "The first draft of the model will exclude the input transform and the feature transform.\n",
    "\n",
    "In the following section, please implement the following:\n",
    "- Complete the SharedMLP Class: This will include adding the appropriate number of layers, a BatchNorm, and ReLU activation function\n",
    "- Complete the forward function for the BaselineClassificationNN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38677f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Sequential):\n",
    "    def __init__(self, layer_sizes, dropout=0.7):\n",
    "        layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            layers.append(nn.BatchNorm1d(layer_sizes[i+1]))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            layers.append(nn.ReLU())\n",
    "        super(MLP, self).__init__(*layers)\n",
    "            \n",
    "\n",
    "class SharedMLP(nn.Sequential):\n",
    "    def __init__(self, layer_sizes):\n",
    "        layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            layers.append(nn.Conv1d(layer_sizes[i], layer_sizes[i+1], 1))\n",
    "            layers.append(nn.BatchNorm1d(layer_sizes[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        super(SharedMLP, self).__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f1c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineClassificationNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaselineClassificationNN, self).__init__()\n",
    "        \n",
    "        self.shared_mlp_1 = SharedMLP([3, 64, 64])\n",
    "        self.shared_mlp_2 = SharedMLP([64, 64, 128, 1024])\n",
    "        self.mlp = MLP([1024, 512, 256, num_classes])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        feat_out = self.shared_mlp_1(x)\n",
    "        out = self.shared_mlp_2(feat_out)\n",
    "        out = F.max_pool1d(out, x.size(-1)).view(x.size(0), -1)\n",
    "        out = self.mlp(out)\n",
    "        return out, feat_out\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eaca58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7b185bf8c34256b0ef6d7f1a67bc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_model = BaselineClassificationNN(10)\n",
    "lr = 0.0001\n",
    "epochs = 1\n",
    "device = 'cpu'\n",
    "\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=lr)\n",
    "train(baseline_model, trainset, validset, optimizer, epochs=epochs, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff7c73",
   "metadata": {},
   "source": [
    "### 2.2 Add Input Transform\n",
    "\n",
    "In the following section, please implement the following:\n",
    "- Complete the TNet Class: This will include adding the appropriate number of layers, a BatchNorm, and ReLU activation function\n",
    "- Modify the BaselineClassificationNN to include the Input Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T_net(nn.Module):\n",
    "    def __init__(self, size, dropout=0.7, bn_momentum=None):\n",
    "        super(T_net, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "        self.shared_mlp = SharedMLP([size, 64, 128, 1024])\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, size*size, bias=False)\n",
    "        self.fc3.requires_grad_(False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512, momentum=bn_momentum)\n",
    "        self.bn2 = nn.BatchNorm1d(256, momentum=bn_momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            Input: B x size x N\n",
    "        '''\n",
    "        out = self.shared_mlp(x)\n",
    "        out = F.max_pool1d(out, kernel_size=x.size(-1))\n",
    "        out = out.view(-1, 1024)\n",
    "        out = F.relu(self.bn1(self.fc1(out)))\n",
    "        out = F.relu(self.bn2(self.fc2(out)))\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        out = out.view(-1, self.size, self.size)\n",
    "        bias = torch.eye(self.size, requires_grad=True).expand(x.size(0), -1, -1)\n",
    "        return out + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3fd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InputTransform, self).__init__()\n",
    "        self.T_net = T_net(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.T_net(x)\n",
    "        return torch.bmm(x.transpose(1, 2), out).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputTransformClassificationNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(InputTransformClassificationNN, self).__init__()\n",
    "        self.input_transform = InputTransform()\n",
    "        self.shared_mlp_1 = SharedMLP([3, 64, 64])\n",
    "        self.shared_mlp_2 = SharedMLP([64, 64, 128, 1024])\n",
    "        self.mlp = MLP([1024, 512, 256, num_classes])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.input_transform(x)\n",
    "        feat_out = self.shared_mlp_1(out)\n",
    "        out = self.shared_mlp_2(feat_out)\n",
    "        out = F.max_pool1d(out, x.size(-1)).view(x.size(0), -1)\n",
    "        out = self.mlp(out)\n",
    "        return out, feat_out\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transform_model = InputTransformClassificationNN(10)\n",
    "lr = 0.0001\n",
    "epochs = 1\n",
    "device = 'cpu'\n",
    "\n",
    "optimizer = torch.optim.Adam(input_transform_model.parameters(), lr=lr)\n",
    "train(input_transform_model, trainset, validset, optimizer, epochs=epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2 Add Feature Transform\n",
    "\n",
    "In the following section, please implement the following:\n",
    "- Complete the FeatureTransform Class\n",
    "- Update the FeatureTransformClassificationNN to include the Feature Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f408b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureTransform, self).__init__()\n",
    "        self.T_net = T_net(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.T_net(x)\n",
    "        self.A = out\n",
    "        return torch.bmm(x.transpose(1, 2), out).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a20e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullClassificationNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FullClassificationNN, self).__init__()\n",
    "        self.input_transform = InputTransform()\n",
    "        self.feature_transform = FeatureTransform()\n",
    "        self.shared_mlp_1 = SharedMLP([3, 64, 64])\n",
    "        self.shared_mlp_2 = SharedMLP([64, 64, 128, 1024])\n",
    "        self.mlp = MLP([1024, 512, 256, num_classes])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.input_transform(x)\n",
    "        out = self.shared_mlp_1(out)\n",
    "        feat_out = self.feature_transform(out)\n",
    "        out = self.shared_mlp_2(feat_out)\n",
    "        out = F.max_pool1d(out, x.size(-1)).view(x.size(0), -1)\n",
    "        out = self.mlp(out)\n",
    "        return out, feat_out\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = FullClassificationNN(10)\n",
    "lr = 0.0001\n",
    "epochs = 1\n",
    "device = 'cpu'\n",
    "\n",
    "optimizer = torch.optim.Adam(full_model.parameters(), lr=lr)\n",
    "train(full_model, trainset, validset, optimizer, epochs=epochs, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49936e0",
   "metadata": {},
   "source": [
    "### 2.4 Update the Task for Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738fa30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationNN(nn.Module):\n",
    "    def __init__(self, num_features: int):\n",
    "        super(SegmentationNN, self).__init__()\n",
    "        self.input_transform = InputTransform()\n",
    "        self.feature_transform = FeatureTransform()\n",
    "\n",
    "        self.mlp_1 = SharedMLP([3, 64, 64])\n",
    "        self.mlp_2 = SharedMLP([64, 64, 128, 1024])\n",
    "        self.mlp_3 = SharedMLP([1088, 512, 256, 128])\n",
    "        self.mlp_4 = SharedMLP([128, 128, num_features])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.input_transform(x)\n",
    "        out = self.mlp_1(out)\n",
    "        feat_out = self.feature_transform(out)\n",
    "        global_feature = self.mlp_2(out)\n",
    "        global_feature = F.max_pool1d(global_feature, x.size(2))\n",
    "        global_feature = global_feature.expand(-1, -1, x.size(-1))\n",
    "        out = torch.cat([out, global_feature], 1)\n",
    "        out = self.mlp_3(out)\n",
    "        out = self.mlp_4(out)\n",
    "        return out, feat_out\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "\n",
    "trainset = ShapeNetDataset(\"datasets/ModelNet10\", train=True, n=n)\n",
    "testset = ShapeNetDataset(\"datasets/ModelNet10\", train=False, n=n)\n",
    "\n",
    "dataset_length = len(trainset)\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.3\n",
    "\n",
    "train_len = int(dataset_length * train_ratio)\n",
    "valid_len = dataset_length - train_len\n",
    "\n",
    "\n",
    "\n",
    "trainset, validset = random_split(trainset, [train_len, valid_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e726d6",
   "metadata": {},
   "source": [
    "# Remaining Items To-Do\n",
    "- Improve the implementation of Model2\n",
    "- Finalize the Segmentation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f79c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09c46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs182",
   "language": "python",
   "name": "cs182"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
