{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b16444",
   "metadata": {},
   "source": [
    "# Point Net Homework\n",
    "\n",
    "The following homework is based on the paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Qi et al.\n",
    "\n",
    "In this paper, the authors present a novel neural network architecture that takes in point clouds as inputs. This network can be used across many tasks including object segmentation, part segmentation, and scene semantic parsing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c845ad7",
   "metadata": {},
   "source": [
    "## 1. 3D Data Representation\n",
    "\n",
    "There are various ways one could represent 3D before inputting into a neural network. Histocially, networks have used convolutional architecures, which require inputs to be highly standardized. As such, researchers will often convert their data into 3D voxel grids or collections of images. \n",
    "\n",
    "As stated by the authors, these data formats are volumous, due to data redundancy, and may introduce quantization artifacts. As such, we will be focusing on 3D Meshes and Point Clouds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd300e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyvista\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install trame\n",
    "!pip install pytorch_model_summary\n",
    "!pip install matplotlib==3.5.0\n",
    "!pip install pyntcloud\n",
    "\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.append('./pretrained')\n",
    "from test_semseg import main as pretrained_sem\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec649b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_model_summary import summary\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from pyntcloud import PyntCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac29904",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d7f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "teapot_file_path = '../cs182-proj/images/canvas3D-master/teapot.ply'\n",
    "points_data = pv.read(teapot_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf4e47",
   "metadata": {},
   "source": [
    "### 3D Mesh\n",
    "\n",
    "The 3D Mesh is generated using a set of polygons to represent the structure of the object. It is determined using points with X, Y, Z coordinates. These points are connected to make polygons, most commonly triangles and quads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f471334",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_data.plot(jupyter_backend='panel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a0796",
   "metadata": {},
   "source": [
    "### Point Cloud\n",
    "Point Clouds are a basic data format in which the points are represented in 3D space, using X, Y, and Z coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere = pv.Sphere(radius=0.05)\n",
    "pc = points_data.glyph(scale=False, geom=sphere, orient=False)\n",
    "pc.plot(cmap='Reds', jupyter_backend='panel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ae23d",
   "metadata": {},
   "source": [
    "The authors in the paper chose to use Point Clouds instead of a 3D Mesh. **Looking at the objects, why would they choose to do so?**\n",
    "\n",
    "Solution: 3D Meshes have additional complexity and combinations that must be carried through, thereby drastically increasing the complexity of the data format. Further, there is likely little value add by including this additional information outside of for visualization purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295b173c",
   "metadata": {},
   "source": [
    "## 2. The Model Architecture\n",
    "\n",
    "The archicture of PointNet is as follows:\n",
    "![plot](images/model.png)\n",
    "\n",
    "In the paper, the authors used the ModelNet10 dataset and the ModelNet40 dataset. The ModelNet10 dataset has 10 classes of varying objects.\n",
    "\n",
    "![plot](images/class_detail.png)\n",
    "\n",
    "However, given the size of the dataset, it is not feasible to train the entire model in the context of this homework. As such, we have modified the dataset to be a binary classification problem: bathtub or table.\n",
    "\n",
    "In the following sections we will implement pieces of the architecture and see how they impact the downstream performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00fb91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeNetDataset(Dataset):\n",
    "    def __init__(self, root, train=True, n=10000):\n",
    "        classes = [c for c in os.listdir(root) \n",
    "                   if os.path.isdir(os.path.join(root, c))]\n",
    "        self.classes = {k: c for k, c in enumerate(classes)}\n",
    "        self.path = root\n",
    "        self.train = train\n",
    "        self.n = n\n",
    "        self.df = pd.DataFrame()\n",
    "        for label, c in self.classes.items():\n",
    "            path = None\n",
    "            if self.train:\n",
    "                path = os.path.join(self.path, c, \"train\")\n",
    "            else:\n",
    "                path = os.path.join(self.path, c, \"test\")\n",
    "            dir_list = [dir for dir in os.listdir(path) if dir.endswith('.off')]\n",
    "            label_list = [label]*len(dir_list)\n",
    "            df = pd.DataFrame(list(zip(dir_list, label_list)), columns=['path', 'label'])\n",
    "            self.df = pd.concat((self.df, df))\n",
    "        self.df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Returns (3 X N, label)\n",
    "        '''\n",
    "        path, label = self.df.loc[idx, 'path'], self.df.loc[idx, 'label']\n",
    "        get_file = lambda p, t: PyntCloud.from_file(os.path.join(self.path, self.classes[label], t, p))\n",
    "        test_train = 'train' if self.train else 'test'\n",
    "        pointcloud = get_file(path, test_train).get_sample('mesh_random', n=self.n)\n",
    "        return torch.Tensor(pointcloud.values).transpose(0,1), label  \n",
    "\n",
    "class Logger():\n",
    "    def __init__(self):\n",
    "        self._log = {'train loss': [], \n",
    "                     'valid loss': [], \n",
    "                     'train accuracy': [], \n",
    "                     'valid accuracy': []}\n",
    "    \n",
    "    def log(self, name: str, value):\n",
    "        if name not in self._log.keys():\n",
    "            raise NotImplementedError\n",
    "        self._log[name].append(value)\n",
    "\n",
    "    def plot_loss(self):\n",
    "        train_loss, valid_loss = self._log['train loss'], self._log['valid loss']\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.suptitle('Iterations vs Loss')\n",
    "        fig.supxlabel('Iterations')\n",
    "        fig.supylabel('Loss')\n",
    "        ax1.plot(range(len(train_loss)), train_loss, label='training')\n",
    "        ax1.set_title('Training')\n",
    "        ax2.plot(range(len(valid_loss)), valid_loss, label='validation')\n",
    "        ax2.set_title('Validation')\n",
    "\n",
    "    def plot_accuracy(self):\n",
    "        train_acc, valid_acc = self._log['train accuracy'], self._log['valid accuracy']\n",
    "        plt.plot(range(len(train_acc)), train_acc, label='training')\n",
    "        plt.plot(range(len(valid_acc)), valid_acc, label='validation')\n",
    "        plt.title('Epochs vs Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "    \n",
    "def BatchPyntCloudToTensor(pyntcloud):\n",
    "    # B x PyntCloud(N X 3) -> B x 3 X N \n",
    "    pointcloud = pyntcloud.points.values\n",
    "    return torch.Tensor(pointcloud).transpose(1, 2)\n",
    "\n",
    "\n",
    "# class S3DISDataset(Dataset): /datautils\n",
    "#     # you can download dataset through this google form http://buildingparser.stanford.edu/dataset.html\n",
    "# and here we might use the dataloader with reference from https://github.com/yanx27/Pointnet_Pointnet2_pytorch/blob/master/data_utils/S3DISDataLoader.py\n",
    "# /datautils need to be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(preds, labels, feature_transform, reg=0.0001):\n",
    "    #loss = torch.nn.NLLLoss()\n",
    "    target_ar = np.zeros(preds.shape)\n",
    "    for i in range(target_ar.shape[0]):\n",
    "        label_idx = labels[i]\n",
    "        target_ar[i, label_idx] = 1\n",
    "        \n",
    "    loss = torch.nn.BCELoss()\n",
    "    #loss = torch.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)\n",
    "    def feat_loss(A):\n",
    "        I = torch.eye(64, requires_grad=True).expand(A.size(0), -1, -1).to(device)\n",
    "        AA_T = torch.bmm(A, A.transpose(1, 2))\n",
    "        return torch.linalg.norm(I - AA_T, ord='fro', dim=(1,2))\n",
    "    #return loss(torch.softmax(preds, dim=1), labels) + reg * torch.mean(feat_loss(feature_transform))\n",
    "    #return loss + reg * torch.mean(feat_loss(feature_transform))\n",
    "    return loss(torch.softmax(preds, dim=1), torch.tensor(target_ar).float()) + reg * torch.mean(feat_loss(feature_transform))\n",
    "\n",
    "def train(model, trainset, validset, optimizer, epochs=10, batch_size=32, logger=None):\n",
    "    train_dataloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(validset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_loss, valid_loss = 0.0, 0.0\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        # Train and get training loss and accuracy\n",
    "        train_num_correct = 0\n",
    "        train_count = 0\n",
    "        for x, y in tqdm(train_dataloader, unit='batch'):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred, feat = model(x)\n",
    "            #print(pred)\n",
    "            #print(y)\n",
    "            loss = loss_fn(pred, y, feat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            #print(torch.sum(pred.argmax(1) == y).item())\n",
    "            train_num_correct += torch.sum(pred.argmax(1) == y).item()\n",
    "            train_count += y.shape[0]\n",
    "            logger.log('train loss', train_loss)\n",
    "            train_loss = 0\n",
    "        \n",
    "        logger.log('train accuracy', train_num_correct / train_count)\n",
    "\n",
    "        model.eval()\n",
    "        # Get validation loss and accuracy\n",
    "        with torch.no_grad():\n",
    "            valid_num_correct = 0\n",
    "            valid_count = 0 \n",
    "            for x, y in tqdm(valid_dataloader, unit='batch'):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                pred, feat = model(x)\n",
    "                loss = loss_fn(pred, y, feat)\n",
    "                valid_loss += loss.item()\n",
    "                #print(pred.argmax(1))\n",
    "                #print(y)\n",
    "                valid_num_correct += torch.sum(pred.argmax(1) == y).item()\n",
    "                valid_count += y.shape[0]\n",
    "                logger.log('valid loss', valid_loss)\n",
    "                \n",
    "                valid_loss = 0\n",
    "                \n",
    "        logger.log('valid accuracy', valid_num_correct / valid_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b635eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "num_classes = 2\n",
    "epochs = 2\n",
    "lr = 0.0001\n",
    "device = 'cpu'\n",
    "\n",
    "trainset = ShapeNetDataset(\"datasets/ModelNet2\", train=True, n=n)\n",
    "testset = ShapeNetDataset(\"datasets/ModelNet2\", train=False, n=n)\n",
    "\n",
    "dataset_length = len(trainset)\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.3\n",
    "\n",
    "train_len = int(dataset_length * train_ratio)\n",
    "valid_len = dataset_length - train_len\n",
    "\n",
    "trainset, validset = random_split(trainset, [train_len, valid_len])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e681d9",
   "metadata": {},
   "source": [
    "### 2.1 Baseline Architecture\n",
    "\n",
    "The first draft of the model will exclude the input transform and the feature transform.\n",
    "\n",
    "Baseline Architecture:\n",
    "![plot](images/baseline_network.png)\n",
    "\n",
    "In the following section, please implement the following:\n",
    "- Complete the SharedMLP Class: This will include adding the appropriate number of layers, a BatchNorm, and ReLU activation function\n",
    "- Complete the forward function for the BaselineClassificationNN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Sequential):\n",
    "    def __init__(self, layer_sizes, dropout=0.7):\n",
    "        layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            layers.append(nn.BatchNorm1d(layer_sizes[i+1]))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            layers.append(nn.ReLU())\n",
    "        super(MLP, self).__init__(*layers)\n",
    "            \n",
    "\n",
    "class SharedMLP(nn.Sequential):\n",
    "    def __init__(self, layer_sizes):\n",
    "        layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            layers.append(nn.Conv1d(layer_sizes[i], layer_sizes[i+1], 1))\n",
    "            layers.append(nn.BatchNorm1d(layer_sizes[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        super(SharedMLP, self).__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineClassificationNN(nn.Module):\n",
    "    def __init__(self, num_classes, pool_type='max'):\n",
    "        super(BaselineClassificationNN, self).__init__()\n",
    "        \n",
    "        ##################################################\n",
    "        # TO DO:\n",
    "        # Update the dimensions for the MLP layers below using the architecture\n",
    "        ##################################################\n",
    "        #self.shared_mlp_1 = SharedMLP([...])\n",
    "        #self.shared_mlp_2 = SharedMLP([...])\n",
    "        #self.mlp = MLP([...])\n",
    "        \n",
    "        self.pool_type = pool_type\n",
    "        self.shared_mlp_1 = SharedMLP([3, 64, 64])\n",
    "        self.shared_mlp_2 = SharedMLP([64, 64, 128, 1024])\n",
    "        self.mlp = MLP([1024, 512, 256, num_classes])\n",
    "        \n",
    "        ##################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ##################################################\n",
    "        # TO DO:\n",
    "        # Create the forward function\n",
    "        # For the baseline model, please follow the architecture diagram for the\n",
    "        # Here, we will skip the Input Transform and the Feature Transform\n",
    "        # Notice that we have a pool_type parameter which can be either \"max\" or \"avg\"\n",
    "        # Please include an if statement accordingly\n",
    "        \n",
    "        #Note that the feat_out will be part of the regularizer.\n",
    "        #In the original architecture, the feat_out will be the output of the feature transform\n",
    "        #Howver, here since we have not yet implemented the feature transform, please set feat_out\n",
    "        #to be the output of of the first MLP\n",
    "        \n",
    "        ##################################################\n",
    "\n",
    "        feat_out = self.shared_mlp_1(x)\n",
    "        out = self.shared_mlp_2(feat_out)\n",
    "        if self.pool_type == 'max':\n",
    "            out = F.max_pool1d(out, x.size(-1)).view(x.size(0), -1)\n",
    "        elif self.pool_type == 'avg':\n",
    "            out = F.avg_pool1d(out, x.size(-1)).view(x.size(0), -1)\n",
    "        out = self.mlp(out)\n",
    "\n",
    "        ##################################################\n",
    "        \n",
    "        return out, feat_out\n",
    "    \n",
    "        \n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c1fe14",
   "metadata": {},
   "source": [
    "**Baseline Test Case:**\n",
    "\n",
    "Before training the baseline model, run the following test case to make sure your implementation is correct with respect to tensor dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testBaselineClassificationNN():\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    batch_size = 5\n",
    "    input_channels = 3\n",
    "    input_length = 20\n",
    "    num_classes = 10\n",
    "    \n",
    "    x = torch.arange(1, 301, 1).view(batch_size, input_channels, input_length).float()\n",
    "    model = BaselineClassificationNN(num_classes)\n",
    "    output, features_out = model.forward(x)\n",
    "\n",
    "    expected_output = torch.tensor([\n",
    "    [0.0000, 0.0000, -0.0000, 5.2441, -0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000],\n",
    "    [0.7500, 0.0000, 0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, 0.0000, -0.0000],\n",
    "    [0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000],\n",
    "    [0.0000, -0.0000, 0.6712, 0.0000, -0.0000, 0.0000, -0.0000, 1.7654, -0.0000, 0.0000],\n",
    "    [0.6772, 4.4127, 0.0000, 0.0000, 0.0000, 3.8785, 0.0000, 0.0000, 0.0000, -0.0000]\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "\n",
    "    assert torch.all(torch.isclose(output, expected_output, atol=1e-3)), \"Output tensor values not close to expected value.\"\n",
    "    assert output.size() == (batch_size, num_classes), \"Output tensor has incorrect dimensions.\"\n",
    "    assert features_out.size() == (batch_size, 64, input_length), \"Feature tensor has incorrect dimensions.\"\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "testBaselineClassificationNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556078e",
   "metadata": {},
   "source": [
    "**Train the Avg Pool Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad49fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = BaselineClassificationNN(num_classes, pool_type='avg')\n",
    "logger = Logger()\n",
    "\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=lr)\n",
    "train(baseline_model, trainset, validset, optimizer, epochs=epochs, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.plot_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696dd3b",
   "metadata": {},
   "source": [
    "**Train Model with Max Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = BaselineClassificationNN(num_classes, pool_type='max')\n",
    "logger = Logger()\n",
    "\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=lr)\n",
    "train(baseline_model, trainset, validset, optimizer, epochs=epochs, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac58a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.plot_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5aada",
   "metadata": {},
   "source": [
    "### 2.2 Add Input Transform\n",
    "\n",
    "In the following section, please implement the following:\n",
    "\n",
    "Input Transform Architecture:\n",
    "![plot](images/add_input_transform.png)\n",
    "\n",
    "- Complete the TNet Class: This will include adding the appropriate number of layers, a BatchNorm, and ReLU activation function\n",
    "- Modify the BaselineClassificationNN to include the Input Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T_net(nn.Module):\n",
    "    def __init__(self, size, dropout=0.7, bn_momentum=None):\n",
    "        super(T_net, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "        self.shared_mlp = SharedMLP([size, 64, 128, 1024])\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, size*size, bias=False)\n",
    "        self.fc3.requires_grad_(False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512, momentum=bn_momentum)\n",
    "        self.bn2 = nn.BatchNorm1d(256, momentum=bn_momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            Input: B x size x N\n",
    "        '''\n",
    "        out = self.shared_mlp(x)\n",
    "        out = F.max_pool1d(out, kernel_size=x.size(-1))\n",
    "        out = out.view(-1, 1024)\n",
    "        out = F.relu(self.bn1(self.fc1(out)))\n",
    "        out = F.relu(self.bn2(self.fc2(out)))\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        out = out.view(-1, self.size, self.size)\n",
    "        bias = torch.eye(self.size, requires_grad=True).expand(x.size(0), -1, -1).to(device)\n",
    "        return out + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InputTransform, self).__init__()\n",
    "        self.T_net = T_net(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ##################################################\n",
    "        # TO DO:\n",
    "        # Create the forward function\n",
    "        # In this function, we will run the input through the model\n",
    "        # then element-wise multiply the original input with the output\n",
    "        # torch.bmm could be useful here\n",
    "        # You may also need to transpose the data\n",
    "        ##################################################\n",
    "        \n",
    "        out = self.T_net(x)\n",
    "        return torch.bmm(x.transpose(1, 2), out).transpose(1, 2)\n",
    "    \n",
    "        ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputTransformClassificationNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(InputTransformClassificationNN, self).__init__()\n",
    "        self.input_transform = InputTransform()\n",
    "        self.shared_mlp_1 = SharedMLP([3, 64, 64])\n",
    "        self.shared_mlp_2 = SharedMLP([64, 64, 128, 1024])\n",
    "        self.mlp = MLP([1024, 512, 256, num_classes])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ##################################################\n",
    "        # TO DO:\n",
    "        # Create the forward function\n",
    "        # You can copy and paste the code from the baseline class above and add the Input Transform\n",
    "        # again here, the feat_out will be the ouput of the first MLP\n",
    "        ##################################################\n",
    "\n",
    "        out = self.input_transform(x)\n",
    "        feat_out = self.shared_mlp_1(out)\n",
    "        out = self.shared_mlp_2(feat_out)\n",
    "        out = F.max_pool1d(out, x.size(-1)).view(x.size(0), -1)\n",
    "        out = self.mlp(out)\n",
    "        \n",
    "        ##################################################\n",
    "        \n",
    "        return out, feat_out\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66317694",
   "metadata": {},
   "source": [
    "**Input Transform Test Case**\n",
    "\n",
    "Before training the baseline model with the input transform added, run the following test case to make sure your implementation is correct with respect to tensor dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63fa506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testInputTransformClassificationNN():\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    batch_size = 5\n",
    "    input_channels = 3\n",
    "    input_length = 20\n",
    "    num_classes = 10\n",
    "    \n",
    "    x = torch.arange(1, 301, 1).view(batch_size, input_channels, input_length).float()\n",
    "    model = InputTransformClassificationNN(num_classes)\n",
    "    output, features_out = model.forward(x)\n",
    "    \n",
    "    expected_output = torch.tensor([[0.0000, 0.0000, 3.8678, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "     0.0000],\n",
    "    [0.0000, -0.0000, 1.2132, 0.0000, 2.7523, 4.5780, 0.0000, 0.0000, -0.0000,\n",
    "     0.0000],\n",
    "    [-0.0000, 5.2818, 0.0000, 0.0000, 0.0000, 0.2553, 0.0000, -0.0000, 0.0000,\n",
    "     0.0000],\n",
    "    [-0.0000, -0.0000, -0.0000, 0.9948, -0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "     -0.0000],\n",
    "    [4.2480, 2.4292, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
    "     -0.0000]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "    assert torch.all(torch.isclose(output, expected_output, atol=1e-3)), \"Output tensor values not close to expected value.\"\n",
    "    assert output.size() == (batch_size, num_classes), \"Output tensor has incorrect dimensions.\"\n",
    "    assert features_out.size() == (batch_size, 64, input_length), \"Feature tensor has incorrect dimensions.\"\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "testInputTransformClassificationNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da48c92",
   "metadata": {},
   "source": [
    "**Train the Input Transform Classification Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f50cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transform_model = InputTransformClassificationNN(num_classes)\n",
    "logger = Logger()\n",
    "\n",
    "optimizer = torch.optim.Adam(input_transform_model.parameters(), lr=lr)\n",
    "train(input_transform_model, trainset, validset, optimizer, epochs=epochs, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec72ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.plot_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4985ca2",
   "metadata": {},
   "source": [
    "### 2.2 Add Feature Transform\n",
    "\n",
    "In the following section, please implement the following:\n",
    "- Complete the FeatureTransform Class\n",
    "- Update the FeatureTransformClassificationNN to include the Feature Transform\n",
    "\n",
    "Full Classification Architecture:\n",
    "![plot](images/full_classification.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c033845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureTransform, self).__init__()\n",
    "        self.T_net = T_net(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.T_net(x)\n",
    "        self.A = out\n",
    "        return torch.bmm(x.transpose(1, 2), out).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullClassificationNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FullClassificationNN, self).__init__()\n",
    "        self.input_transform = InputTransform()\n",
    "        self.feature_transform = FeatureTransform()\n",
    "        self.shared_mlp_1 = SharedMLP([3, 64, 64])\n",
    "        self.shared_mlp_2 = SharedMLP([64, 64, 128, 1024])\n",
    "        self.mlp = MLP([1024, 512, 256, num_classes])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.input_transform(x)\n",
    "        out = self.shared_mlp_1(out)\n",
    "        feat_out = self.feature_transform(out)\n",
    "        out = self.shared_mlp_2(feat_out)\n",
    "        out = F.max_pool1d(out, x.size(-1)).view(x.size(0), -1)\n",
    "        out = self.mlp(out)\n",
    "        return out, feat_out\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af022a",
   "metadata": {},
   "source": [
    "**Full Classification Network Test Case**\n",
    "\n",
    "Before training the full network model, run the following test case to make sure your implementation is correct with respect to tensor dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFullClassificationNN():\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    batch_size = 5\n",
    "    input_channels = 3\n",
    "    input_length = 20\n",
    "    num_classes = 10\n",
    "    \n",
    "    x = torch.arange(1, 301, 1).view(batch_size, input_channels, input_length).float()\n",
    "    model = InputTransformClassificationNN(num_classes)\n",
    "    output, features_out = model.forward(x)\n",
    "\n",
    "    expected_output = torch.tensor([[0.0000, 0.0000, 3.8678, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000], [0.0000, -0.0000, 1.2132, 0.0000, 2.7523, 4.5780, 0.0000, 0.0000, -0.0000,\n",
    "         0.0000], [-0.0000, 5.2818, 0.0000, 0.0000, 0.0000, 0.2553, 0.0000, -0.0000, 0.0000,\n",
    "         0.0000],[-0.0000, -0.0000, -0.0000, 0.9948, -0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         -0.0000],[4.2480, 2.4292, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
    "         -0.0000]], dtype=torch.float32)\n",
    "\n",
    "    assert torch.all(torch.isclose(output, expected_output, atol=1e-3)), \"Output tensor values not close to expected value.\"\n",
    "    assert output.size() == (batch_size, num_classes), \"Output tensor has incorrect dimensions.\"\n",
    "    assert features_out.size() == (batch_size, 64, input_length), \"Feature tensor has incorrect dimensions.\"\n",
    "    print(\"Test passed!\")\n",
    "\n",
    "testFullClassificationNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32055c9c",
   "metadata": {},
   "source": [
    "**Train the Full Classification Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67051d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = FullClassificationNN(num_classes)\n",
    "logger = Logger()\n",
    "\n",
    "optimizer = torch.optim.Adam(full_model.parameters(), lr=lr)\n",
    "train(full_model, trainset, validset, optimizer, epochs=epochs, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.plot_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3492599f",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41b9d0",
   "metadata": {},
   "source": [
    "###### ![plot](images/model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b708f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationNN(nn.Module):\n",
    "    def __init__(self, num_features: int):\n",
    "        super(SegmentationNN, self).__init__()\n",
    "        self.input_transform = InputTransform()\n",
    "        self.feature_transform = FeatureTransform()\n",
    "\n",
    "        self.mlp_1 = SharedMLP([3, 64, 64])\n",
    "        self.mlp_2 = SharedMLP([64, 64, 128, 1024])\n",
    "        ####################################\n",
    "        # Complete the PointNet for Semantic Segmentation.\n",
    "        # Hint: a. You can use the SharedMLP Structure that we've already implemented above\n",
    "        # 1. self.mlp_3 = SharedMLP([?, ?, ?, ?])\n",
    "        # 2. self.mlp_4 = SharedMLP([?, ?, ?])\n",
    "        # Hint: b. Think about the yellow part in the above diagram.\n",
    "        ####################################\n",
    "        self.mlp_3 = SharedMLP([1088, 512, 256, 128])\n",
    "        self.mlp_4 = SharedMLP([128, 128, num_features])\n",
    "        ####################################\n",
    "        # End of Your Code\n",
    "        ####################################\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.input_transform(x)\n",
    "        out = self.mlp_1(out)\n",
    "        feat_out = self.feature_transform(out)\n",
    "        global_feature = self.mlp_2(out)\n",
    "        ####################################\n",
    "        # Implement the forward function\n",
    "        # Hint: you need to flatten the global features\n",
    "        # and then concat it with the transformed feature.\n",
    "        # You may find F.max_pool1d useful for this task.\n",
    "        ####################################\n",
    "        global_feature = F.max_pool1d(global_feature, x.size(2))\n",
    "        global_feature = global_feature.expand(-1, -1, x.size(-1))\n",
    "        out = torch.cat([out, global_feature], 1)\n",
    "        ####################################\n",
    "        # End of Your Code\n",
    "        ####################################\n",
    "        out = self.mlp_3(out)\n",
    "        out = self.mlp_4(out)\n",
    "        return out, feat_out\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99db6c13",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFullSegmentationNN():\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    rand_data = Variable(torch.rand(32, 3, 100)) # B X 3 X N\n",
    "    seg_net = SegmentationNN(num_features=10)\n",
    "    out = seg_net(rand_data)\n",
    "\n",
    "    expected_output = torch.tensor([0.1700, 0.2135, 0.0000, 0.1433, 0.4386, 0.1360, 0.0000, 0.1846, 0.0667,\n",
    "            0.0000, 0.0000, 0.3241, 0.2135, 0.0000, 0.0642, 0.0000, 0.3772, 0.0000,\n",
    "            0.0000, 0.1300, 0.5210, 0.0000, 0.4803, 0.2122, 0.0000, 0.0000, 0.0000,\n",
    "            0.0000, 0.2493, 0.3928, 0.0000, 0.0000, 0.0000, 0.0796, 0.0000, 0.3825,\n",
    "            0.0000, 0.0000, 0.3236, 0.2709, 0.3733, 0.0000, 0.2975, 0.1212, 0.3352,\n",
    "            0.5593, 0.2150, 0.2737, 0.3039, 0.0000, 0.5902, 0.2052, 0.2062, 0.1454,\n",
    "            0.3114, 0.0000, 0.2753, 0.4174, 0.0551, 0.0000, 0.1145, 0.5573, 0.0941,\n",
    "            0.0000, 0.3606, 0.0000, 0.3064, 0.6121, 0.5824, 0.0520, 0.3984, 0.3791,\n",
    "            0.0622, 0.0000, 0.0000, 0.1183, 0.0000, 0.3488, 0.1205, 0.0000, 0.5914,\n",
    "            0.6549, 0.4512, 0.2345, 0.2802, 0.5435, 0.2331, 0.0000, 0.0000, 0.5155,\n",
    "            0.4543, 0.3381, 0.1756, 0.0000, 0.0000, 0.3362, 0.3292, 0.3350, 0.6082,\n",
    "            0.6131])\n",
    "\n",
    "    assert out[0].size()==(32,10,100)\n",
    "    assert out[1].size()==(32,64,100)\n",
    "    assert torch.all(torch.isclose(out[0][0][0], expected_output, atol=1e-3)), \"Output tensor values not close to expected value.\"\n",
    "    print(\"Test passed!\") \n",
    "\n",
    "testFullSegmentationNN()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f089ad0",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "- what's the number of trainable params of our model with num_features = 10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91422c",
   "metadata": {},
   "source": [
    "# Load Pretrained Model\n",
    "Since the data which is used to train semantic segmentation model is around 13GB, and might take you about 1.5 hour to download it from http://buildingparser.stanford.edu/dataset.html. \n",
    "So here we directly show the result of a pretrained model from the following repo: https://github.com/yanx27/Pointnet_Pointnet2_pytorch/blob/master/log/sem_seg/pointnet_sem_seg/checkpoints/best_model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a0dfe",
   "metadata": {},
   "source": [
    "# Visualize the Segmented Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista\n",
    "from pyvista import examples\n",
    "mesh = pyvista.read('./pretrained/log/sem_seg/pointnet_sem_seg/visual/Area_5_storage_3_pred.obj')\n",
    "mesh.plot(cpos='xz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7e1bf",
   "metadata": {},
   "source": [
    "If the color is not properly displayed, you can also open the obj file with pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fff20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./pretrained/log/sem_seg/pointnet_sem_seg/visual/Area_5_storage_3_pred.obj', \n",
    "                   sep=\" \", header=None, names=['v','x','y','z','R','G','B']).drop(columns=['v'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b63e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PointSet from the DataFrame\n",
    "point_set = pyvista.PolyData(df[['x', 'y', 'z']].values)\n",
    "point_set.point_data['rgb'] = df[['R', 'G', 'B']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_set.plot(point_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ccc9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
